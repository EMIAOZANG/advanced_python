{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS-GA-3001 Advanced Python for Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "solution": false
    }
   },
   "source": [
    "Before you turn this problem in, make sure you **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart). You can then run the cells **in order**, during the class.\n",
    "\n",
    "Any textual answers that need to be provided will be marked with \"YOUR ANSWER HERE\". Replace this text with your answer to the question.\n",
    "\n",
    "Any code answers that need to be provided will be marked with:\n",
    "\n",
    "```\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "```\n",
    "\n",
    "Replace all this code with your answer to the question. If you do not answer the question, the `NotImplementedError` exception will be raised, which will indicate to the grader that no answer has been supplied.\n",
    "\n",
    "In many cases, code answers will also have some associated test code. You should execute the tests after you have entered your code in order to ensure that your answer is correct. You should not proceed to the next question until your answer is correct.\n",
    "\n",
    "Finally, insert your Net ID and the Net ID's of any collaborators in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "NET_ID = \"jl6583\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "solution": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Parallel Programming with MPI (Part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Jupyter for MPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Make sure ipyparallel is installed\n",
    "\n",
    "    conda install ipyparallel\n",
    "\n",
    "### 2. Create jupyter profile\n",
    "\n",
    "    jupyter notebook --generate-config\n",
    "    \n",
    "### 3. Add ipyparallel extension\n",
    "    \n",
    "Edit the `jupyter_notebook_config.py` file\n",
    "\n",
    "    nano ~/.jupyter/jupyter_notebook_config.py\n",
    "    \n",
    "Add the following line anywhere:\n",
    "\n",
    "    c.NotebookApp.server_extensions.append('ipyparallel.nbextension')\n",
    "    \n",
    "Save the file and exit.\n",
    "\n",
    "Edit the `jupyter_notebook_config.json` file (create a new one if it doesn't exist):\n",
    "\n",
    "    nano ~/.jupyter/jupyter_notebook_config.json\n",
    "    \n",
    "Add the following line:\n",
    "\n",
    "    {\"NotebookApp\": {\"server_extensions\": [\"ipyparallel.nbextension\"]}}\n",
    "    \n",
    "Save the file and exit.\n",
    "\n",
    "\n",
    "*Note: if `jupyter_notebook_config.json` already exists, find the `\"server_extensions\"` entry and add a comma to the end of the last extension and `\"ipyparallel.nbextension\"` after that.*\n",
    "\n",
    "### 4. Enable the IPython Clusters tab in the Jupyter Notebook\n",
    "\n",
    "    ipcluster nbextension enable\n",
    "    \n",
    "### 5. Create an MPI profile\n",
    "\n",
    "    ipython profile create --parallel --profile=mpi\n",
    "    \n",
    "### 6. Add MPI to the profile\n",
    "\n",
    "    nano ~/.ipython/profile_mpi/ipcluster_config.py\n",
    "    \n",
    "Add the following line anywhere:\n",
    "\n",
    "    c.IPClusterEngines.engine_launcher_class = 'MPIEngineSetLauncher'\n",
    "    \n",
    "Save the file and exit.\n",
    "\n",
    "### 7. Start the engines\n",
    "\n",
    "    ipcluster start -n 4 --profile=mpi\n",
    "\n",
    "### 8. Restart jupyter notebook\n",
    "\n",
    "Stop the jupyter notebook server, then start a new one.\n",
    "\n",
    "    jupyter notebook\n",
    "    \n",
    "Check that the **IPython Clusters** tab is visible. Switch to this tab and check and there is an **mpi** entry on the tab. Press the refresh button if not:\n",
    "\n",
    "![](http://drive.google.com/uc?export=view&id=0B_3lImS7uRMgamVKb1cyU210S0k)\n",
    "\n",
    "### 9. Start the MPI cluster\n",
    "\n",
    "On the **mpi** entry, set the **# of engines** to **4**, then click the **Start** button. \n",
    "\n",
    "***Note that the # of engines must be less than or equal to the number of engines specified in step 7.***\n",
    "\n",
    "### 10. Initialize MPI\n",
    "\n",
    "Run the following code to initialize MPI. Make sure there are no errors. \n",
    "\n",
    "*** Note: You may need to wait a few seconds after starting the engines before this code will work. Try running it again if you get an error.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from ipyparallel import Client, error\n",
    "cluster = Client(profile=\"mpi\")\n",
    "view = cluster[:]\n",
    "view.block=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Program** - an executable file residing on disk\n",
    "\n",
    "**Process (or task)** - one or more executing instances of a program. Processes have separate address spaces.\n",
    "\n",
    "**Thread (or lightweight process)** - one or more threads of control within a process. Threads share the same address space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://drive.google.com/uc?export=view&id=0B_3lImS7uRMgSFNteVVKaXhCLTg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is parallel computing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traditionally, software has been written for ***serial*** computation:\n",
    "* A problem is broken into a discrete series of instructions\n",
    "* Instructions are executed sequentially one after another\n",
    "* Executed on a single processor\n",
    "* Only one instruction may execute at any moment in time\n",
    "\n",
    "![](http://drive.google.com/uc?export=view&id=0B_3lImS7uRMgcXNYZWtfMHpBdk0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the simplest sense, ***parallel computing*** is the simultaneous use of multiple compute resources to solve a computational problem:\n",
    "* A problem is broken into discrete parts that can be solved concurrently\n",
    "* Each part is further broken down to a series of instructions\n",
    "* Instructions from each part execute simultaneously on different processors\n",
    "* An overall control/coordination mechanism is employed\n",
    "\n",
    "![](http://drive.google.com/uc?export=view&id=0B_3lImS7uRMgUUNKZUdtQnRISEU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we need parallel programming?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to solve larger problems\n",
    "* Require more memory\n",
    "* Computation takes *much* longer\n",
    "* Huge amounts of data may be required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel programming provides\n",
    "* More CPU resources\n",
    "* More memory resources\n",
    "* Solve problems that were not possible with serial program\n",
    "* Solve problems more quickly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two basic approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared Memory Computer\n",
    "* Used by most laptops/PCs\n",
    "* Multiple cores (CPUs)\n",
    "* Share a global memory space\n",
    "* Cores can efficiently exchange/share data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://drive.google.com/uc?export=view&id=0B_3lImS7uRMgaGhfOVo1S0pMT3c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed Memory (ex. Compute cluster)\n",
    "* Collection of nodes which have multiple cores\n",
    "* Each node uses its own local memory\n",
    "* Work together to solve a problem\n",
    "* Communicate between nodes and cores via messages\n",
    "* Nodes are networked together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://drive.google.com/uc?export=view&id=0B_3lImS7uRMgU2VBMVFPS2hVdDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel programming models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directives-based parallel programming language \n",
    "* OpenMP (most widely used)\n",
    "* High Performance Fortran (HPF) is another example\n",
    "* Directives tell processor how to distribute data and work across the processors\n",
    "* Directives appear as comments in the serial code\n",
    "* Implemented on shared memory architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Message Passing\n",
    "* MPI (most widely used)\n",
    "* Pass messages to send/receive data between processes\n",
    "* Each process has its own local variables\n",
    "* Can be used on either shared or distributed memory architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros and cons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pros of OpenMP\n",
    "* Easier to program and debug than MPI\n",
    "* Directives can be added incrementally - gradual parallelization\n",
    "* Can still run the program as a serial code\n",
    "* Serial code statements usually don't need modification\n",
    "* Code is easier to understand and maybe more easily maintained\n",
    "\n",
    "Cons of OpenMP\n",
    "* Can only be run in shared memory computers \n",
    "* Requires a compiler that supports OpenMP\n",
    "* Mostly used for loop parallelization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pros of MPI\n",
    "* Runs on either shared or distributed memory architectures\n",
    "* Can be used on a wider range of problems than OpenMP\n",
    "* Each process has its own local variables\n",
    "* Distributed memory computers are less expensive than large shared memory computers\n",
    "\n",
    "Cons of MPI\n",
    "* Requires more programming changes to go from serial to parallel version\n",
    "* Can be harder to debug\n",
    "* Performance is limited by the communcation network between the nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel programming issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal is to reduce execution time\n",
    "* Computation time\n",
    "* Idle time - waiting for data from other processors\n",
    "* Communication time - time the processors take to send and receive messages\n",
    "\n",
    "Load Balancing \n",
    "* Divide the work equally among the available processors\n",
    "\n",
    "Minimizing Communication\n",
    "* Reduce the number of messages passed \n",
    "* Reduce amount of data passed in messages\n",
    "\n",
    "Where possible - overlap communication and computation\n",
    "\n",
    "Many problems scale well to only a limited number of processors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amdahl's law"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\large\\displaystyle{speedup=\\frac{1}{(1-P)+\\frac{P}{n}}}$\n",
    "\n",
    "where\n",
    "\n",
    "* $speedup$ is the theoretical speedup of the execution of the whole program\n",
    "* $n$ is the number of parallel threads/processes\n",
    "* $P$ is the fraction of the algorithm that can be made parallel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically this is saying that the amount of speedup a program will see by using $n$ cores is based on how much of the program is serial (can only be run on a single CPU core) and how much of it is parallel (can be split up among multiple CPU cores)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://drive.google.com/uc?export=view&id=0B_3lImS7uRMgdXl1Z05reU1aUHc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two main approaches:\n",
    "\n",
    "SPMD - Single Program, Multiple Data Streams\n",
    "* Each processor is executing the same program on different data\n",
    "* A parallel execution model that assumes multiple cooperating processes executing a program\n",
    "* The most common style of parallel programming and the one used by MPI\n",
    "\n",
    "MPMD - Multiple Programs, Multiple Data Streams\n",
    "* Multiple processors executing at least two independent programs\n",
    "* Manager/worker strategies fit into this category\n",
    "* Web browser and web server is another example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is MPI?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPI stands for Message Passing Interface\n",
    "* Library of functions (C/C++) or subroutines (Fortran)\n",
    "\n",
    "History\n",
    "* Early message passing Argonne's P4 and Oak Ridge PVM in 1980s\n",
    "* MPI-1 completed in 1994 (1.1 - 1995, 1.2 - ?, 1.3 - 2008)\n",
    "* MPI-2 completed in 1998 (2.1 - 2008, 2.2 - 2009)\n",
    "* MPI-3 completed in 2012 (3.1 - 2015)\n",
    "\n",
    "MPI-3 features gradually added to MPI implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of  Different Implementations\n",
    "* MPICH - developed by Argonne Nationa Labs (freeware)\n",
    "* MPI/LAM  - developed by Indiana, OSC, Notre Dame (freeware)\n",
    "* MPI/Pro - commerical product\n",
    "* Apple's X Grid \n",
    "* OpenMPI - MPI-2 compliant, thread safe\n",
    "\n",
    "Similiarities in Various Implementations\n",
    "* Source code compatibility (except parallel I/O)\n",
    "* Programs should compile and run as is\n",
    "* Support for heterogeneous parallel architectures\n",
    "\n",
    "Difference in Various Implementations\n",
    "* Commands for compiling and linking\n",
    "* How to launch an MPI program\n",
    "* Parallel I/O (from MPI-2)\n",
    "* Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message passing (MPI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most commonly used method of programming distributed-memory MIMD systems is message passing, or some variant of message passing. MPI is the most widely used standard.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In basic message passing, the processes coordinate their activities by explicitly sending and receiving messages. Explicit sending and receiving messages is known as ***point to point*** communication.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPI's send and receive calls operate in the following manner:\n",
    "1. First, process A decides a message needs to be sent to process B. \n",
    "2. Process A then packs up all of its necessary data into a buffer for process B. \n",
    "3. Process A indicates that the data should be sent to process B by calling the `Send` function. \n",
    "4. Before process B can receive the data, it needs to acknowledge that it wants to receive it. Process B does this by calling the `Recv` function.\n",
    "\n",
    "In this way, every time a process sends a message, there must be a process that also indicates it wants to receive the message. i.e. calls to `Send` and `Recv` are always paired.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://drive.google.com/uc?export=view&id=0B_3lImS7uRMgNVNacS1sdzlPbWc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does a process know where to send a message?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of processes is fixed when an MPI program is first started (there is a way to create more processes, but we will ignore that for now.) Each of the processes is assigned a unique integer starting from 0. This integer is know as the *rank* of the process and is how each process is identified when sending and receiving messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPI processes are arranged in logical collections that define which processes are allowed to send and receive messages. A collection of this type is known as *communicator*. Communicators can be arranged in an hierarchy, but as this is seldom used in MPI, we will not consider it more here. There is one special communicator that exists when an MPI program starts, that contains all the processes in the MPI program. This communicator is called `MPI.COMM_WORLD`. In `mpi4py`, communicators are represented by the `Comm` class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for a process to learn about other processes, MPI provides two methods on a communicator. The first of these is called `Get_size()`, and this returns the total number of processes contained in the communicator (the *size* of the communicator). The second of these is called `Get_rank()`, and this returns the rank of the calling process within the communicator. Note that `Get_rank()` will *return a different value* for every process in the MPI program.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, we will refer to the \"process who's rank is N\" and \"process N\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code obtains the size of the `MPI.COMM_WORLD` communicator, and rank of the process within the communicator. Run this code to see what are the values of `size` and `rank` for each process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "2b482286deee643e330026da549030ad",
     "grade": false,
     "grade_id": "par1",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] size=4, rank=1\n",
      "[stdout:1] size=4, rank=2\n",
      "[stdout:2] size=4, rank=0\n",
      "[stdout:3] size=4, rank=3\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "print 'size=%d, rank=%d' % (size, rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "What do you notice about the order that the program prints the values in? *Hint: try running the program a few times.*\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d4a1a0fdc2dea7e91ac8640863d1ca6d",
     "grade": true,
     "grade_id": "par2",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "source": [
    "The order the values are printed is fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One MPI program, multiple MPI processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When an MPI program is run, each process consists of the same code. However, as we've seen, each process is assigned a different rank. This allows code for each process to be embedded within one program file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code, all processes start with the same two numbers `a` and `b`. However, although there is only one file, each process performs a different computation on the numbers. Process 0 prints the sum of the numbers, process 1 prints the result of multiplying the numbers, and process 2 prints the maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "19e13483b51dc49ae9edfb55ad10e456",
     "grade": false,
     "grade_id": "par3",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] 18.0\n",
      "[stdout:1] 6.0\n",
      "[stdout:2] 9.0\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "from mpi4py import MPI\n",
    "rank = MPI.COMM_WORLD.Get_rank()\n",
    "\n",
    "a = 6.0\n",
    "b = 3.0\n",
    "if rank == 0:\n",
    "        print a + b\n",
    "if rank == 1:\n",
    "        print a * b\n",
    "if rank == 2:\n",
    "        print max(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Write a program in which the processes with even rank print \"Hello\" and the processes with odd rank print \"Goodbye\". Print the rank along with the message (for example \"Goodbye from process 3\"). *Hint: remember that although the number of processes is fixed when the program startes, the exact number is not known until the Get_size() method is called.*\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "1f86d7122bba37cce0a3366c0ab26641",
     "grade": true,
     "grade_id": "par4",
     "locked": false,
     "points": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] rank= 1 Goodbye\n",
      "[stdout:1] rank= 2 Hello\n",
      "[stdout:2] rank= 0 Hello\n",
      "[stdout:3] rank= 3 Goodbye\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "rank = MPI.COMM_WORLD.Get_rank()\n",
    "if rank % 2 == 0:\n",
    "    print 'rank=',rank, 'Hello'\n",
    "else:\n",
    "    print 'rank=',rank,'Goodbye'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point-to-point communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in earlier, the simplest message passing involves two processes: a sender and a receiver. Let us begin by demonstrating a program designed for two processes. One will draw a random number and then send it to the other. We will do this using the routines `Send` and `Recv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] Process 1 drew the number 0.462338781739\n",
      "[stdout:2] \n",
      "Process 0 before receiving has the number 0.0\n",
      "Process 0 received the number 0.462338781739\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "import numpy\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "randNum = numpy.zeros(1) #different process has different local variable space\n",
    "\n",
    "if rank == 1:\n",
    "        randNum = numpy.random.random_sample(1)\n",
    "        print \"Process\", rank, \"drew the number\", randNum[0]\n",
    "        comm.Send(randNum, dest=0)\n",
    "\n",
    "if rank == 0:\n",
    "        print \"Process\", rank, \"before receiving has the number\", randNum[0]\n",
    "        comm.Recv(randNum, source=1)\n",
    "        print \"Process\", rank, \"received the number\", randNum[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Send` and `Recv` functions are referred to as *blocking* functions. If a process calls `Recv` it will simply wait until a message from the corresponding `Send` in received before proceeding. Similarly the `Send` will wait until the message has been reveived by the corresponding `Recv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://drive.google.com/uc?export=view&id=0B_3lImS7uRMgOFJmOVA2Z2JycTQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deadlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `Send` and `Recv` are blocking functions, a very common situation that can occur is called ***deadlock***. This happens when one process is waiting for a message that is never sent. We can see a simple example of this by commenting out the `comm.Send` and running the program below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "import numpy\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "randNum = numpy.zeros(1)\n",
    "\n",
    "if rank == 1:\n",
    "        randNum = numpy.random.random_sample(1)\n",
    "        print \"Process\", rank, \"drew the number\", randNum[0]\n",
    "        #comm.Send(randNum, dest=0)\n",
    "\n",
    "if rank == 0:\n",
    "        print \"Process\", rank, \"before receiving has the number\", randNum[0]\n",
    "        comm.Recv(randNum, source=1)\n",
    "        print \"Process\", rank, \"received the number\", randNum[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "When you run this code, it will hang. In fact, the Jupyter kernel is now locked up, so that if you try to run any other code it will also hang. \n",
    "</div>\n",
    "\n",
    "When this happens, you will need to do the following:\n",
    "1. Open the **IPython Clusters** tab and click on the **Stop** button\n",
    "2. Stop the **ipcluster** command (usually Control-C)\n",
    "3. Stop the **jupyter notebook** command (usually Control-C)\n",
    "4. Close this notebook.\n",
    "5. Rerun **jupyter notebook**\n",
    "6. Rerun **ipcluster start -n 4 --profile=mpi**\n",
    "7. Restart 4 engines on the **IPython Clusters** tab.\n",
    "\n",
    "You will also need to re-run the initialization code again (which has been copied below for convenience)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from ipyparallel import Client, error\n",
    "cluster = Client(profile=\"mpi\")\n",
    "view = cluster[:]\n",
    "view.block=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Send and Recv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously we saw how to send a message from one process to another. Now we're going to try sending a message to a process and receiving a message back again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Modify the previous (working) code so that when the process 0 receives the number, it multiplies it by two and sends it back to process 1. Process 1 should then print out the new value.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://drive.google.com/uc?export=view&id=0B_3lImS7uRMgS0FoSGFvVnRRN3c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a3d0f1043cebc98b216847d352bf92f4",
     "grade": true,
     "grade_id": "par5",
     "locked": false,
     "points": 4,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "Process 1 drew the number 0.393592804058\n",
      "Process 1 received the multiplied number 0.787185608116\n",
      "[stdout:2] \n",
      "Process 0 before receiving has the number 0.0\n",
      "Process 0 received the number 0.393592804058\n",
      "Process 0 Send back the multiplied number\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "import numpy\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "randNum = numpy.zeros(1)\n",
    "\n",
    "if rank == 1:\n",
    "        randNum = numpy.random.random_sample(1)\n",
    "        print \"Process\", rank, \"drew the number\", randNum[0]\n",
    "        comm.Send(randNum, dest=0)\n",
    "        #process 1 tries to receive the number back from process 0\n",
    "        comm.Recv(randNum, source=0)\n",
    "        print 'Process', rank, 'received the multiplied number', randNum[0]\n",
    "        \n",
    "\n",
    "if rank == 0:\n",
    "        print \"Process\", rank, \"before receiving has the number\", randNum[0]\n",
    "        comm.Recv(randNum, source=1)\n",
    "        print \"Process\", rank, \"received the number\", randNum[0]\n",
    "        #process 0 multiplies the number and send it back to 1\n",
    "        comm.Send(randNum*2, dest=1)\n",
    "        print 'Process', rank, 'Send back the multiplied number'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The receiving process does not always need to specify the source when issuing a `Recv`. Instead, the process can accept any message that is being sent my another process. This is done by setting the source to `MPI.ANY_SOURCE`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Try replacing the `source=N` arguments in your program with `source=MPI.ANY_SOURCE` to see if it still works.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "9b102efdd8c518a49b187c5e2130839d",
     "grade": true,
     "grade_id": "par6",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "Process 1 drew the number 0.21132575427\n",
      "Process 1 received the multiplied number 0.422651508541\n",
      "[stdout:2] \n",
      "Process 0 before receiving has the number 0.0\n",
      "Process 0 received the number 0.21132575427\n",
      "Process 0 Send back the multiplied number\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "import numpy\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "randNum = numpy.zeros(1)\n",
    "\n",
    "if rank == 1:\n",
    "        randNum = numpy.random.random_sample(1)\n",
    "        print \"Process\", rank, \"drew the number\", randNum[0]\n",
    "        comm.Send(randNum, dest=0)\n",
    "        #process 1 tries to receive the number back from process 0\n",
    "        comm.Recv(randNum, source=MPI.ANY_SOURCE)\n",
    "        print 'Process', rank, 'received the multiplied number', randNum[0]\n",
    "        \n",
    "\n",
    "if rank == 0:\n",
    "        print \"Process\", rank, \"before receiving has the number\", randNum[0]\n",
    "        comm.Recv(randNum, source=MPI.ANY_SOURCE)\n",
    "        print \"Process\", rank, \"received the number\", randNum[0]\n",
    "        #process 0 multiplies the number and send it back to 1\n",
    "        comm.Send(randNum*2, dest=1)\n",
    "        print 'Process', rank, 'Send back the multiplied number'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Final word on the Send and Recv methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>Comm.<b>Send</b>(buf, dest=0, tag=0)</pre>\n",
    "\n",
    "Performs a basic send. This send is a point-to-point communication. It sends information from exactly one process to exactly one other process.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "* **Comm (MPI comm)** – communicator we wish to query\n",
    "* **buf (choice)** – data to send\n",
    "* **dest (integer)** – rank of destination\n",
    "* **tag (integer)** – message tag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>Comm.<b>Recv</b>(buf, source=0, tag=0, status=None)</pre>\n",
    "\n",
    "Performs a point-to-point receive of data.\n",
    "\n",
    "Parameters:\n",
    "\n",
    "* **Comm (MPI comm)** – communicator we wish to query\n",
    "* **buf (choice)** – initial address of receive buffer (choose receipt location)\n",
    "* **source (integer)** – rank of source\n",
    "* **tag (integer)** – message tag\n",
    "* **status (Status)** - status of object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes there are cases when a process might have to send many different types of messages to another process. Instead of having to go through extra measures to differentiate all these messages, MPI allows senders and receivers to also specify message IDs (known as *tags*) with the message. The receiving process can then request a message with a certain tag number and messages with different tags will be buffered until the process requests them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
