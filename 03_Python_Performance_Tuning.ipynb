{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS-GA-3001 Advanced Python for Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "solution": false
    }
   },
   "source": [
    "Before you turn this problem in, make sure you **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart). You can then either run all cells (in the menubar, select Cell$\\rightarrow$Run All), or run each cell individually, **in order**, during the class.\n",
    "\n",
    "Any textual answers that need to be provided will be marked with \"YOUR ANSWER HERE\". Replace this text with your answer to the question.\n",
    "\n",
    "Any code answers that need to be provided will be marked with:\n",
    "\n",
    "```\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "```\n",
    "\n",
    "Replace all this code with your answer to the question. If you do not answer the question, the `NotImplementedError` exception will be raised, which will indicate to the grader that no answer has been supplied.\n",
    "\n",
    "In many cases, code answers will also have some associated test code. You should execute the tests after you have entered your code in order to ensure that your answer is correct. You should not proceed to the next question until your answer is correct.\n",
    "\n",
    "Finally, insert your name and any collaborators in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "solution": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Performance Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to optimize a program, it is essential to understand where the bottlenecks are. These are the places where the program is spending most of its time. A *profile* is a set of statistics that describes how often and for how long various parts of the program executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Deterministic profiling* is meant to reflect the fact that all function call, function return, and exception events are monitored, and precise timings are made for the intervals between these events (during which time the user’s code is executing). This is in contrast to *statistical profiling* which randomly samples the effective instruction pointer, and deduces where time is being spent. The latter technique traditionally involves less overhead (as the code does not need to be instrumented), but provides only relative indications of where time is being spent.\n",
    "\n",
    "In Python, since there is an interpreter active during execution, the presence of instrumented code is not required to do deterministic profiling. Python automatically provides a hook (optional callback) for each event. In addition, the interpreted nature of Python tends to add so much overhead to execution, that deterministic profiling tends to only add small processing overhead in typical applications. The result is that deterministic profiling is not that expensive, yet provides extensive run time statistics about the execution of a Python program.\n",
    "\n",
    "Call counts (i.e. how many times a function is called) and profiling statistics can be used for a variety of purposes:\n",
    "1. Unusual count numbers can help identify bugs in code.\n",
    "2. High call counts can help to identify possible points where in-lining (unwrapping loops) might benefit. \n",
    "3. Internal time statistics can be used to identify “hot loops” that should be carefully optimized. \n",
    "4. Cumulative time statistics can be used to identify high level errors in the selection of algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python has two standard modules that provide the same profiling interface: `cProfile` and `profile` (the hotshot module is no longer maintained). The `cProfile` module has the lowest overhead, but because it is written in C, may not be as widely available. The `profile` module is written in Python, so has a much higher overhead, but is easier to extend. There is also a newer module, called `line_profiler` that profiles on a line-by-line basis. This module is not part of the standard distribution, so needs to be installed separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `cProfile`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b56688132c9f19684f43a105e96f27dd",
     "grade": false,
     "grade_id": "cprofile_1",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import re\n",
    "cProfile.run('re.compile(\"foo|bar\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line indicates the number of calls were monitored. Of those calls, some were primitive, meaning that the call was not induced via recursion. The next line, **\"`Ordered by: standard name`\"**, indicates that the text string in the last column was used to sort the output. The column headings (from left to right) are:\n",
    "\n",
    "|Heading|Description|\n",
    "|:---------|:----------|\n",
    "|`ncalls`|for the number of calls|\n",
    "|`tottime`|for the total time spent in the given function (and excluding time made in calls to sub-functions)|\n",
    "|`percall`|is the quotient of `tottime` divided by `ncalls`|\n",
    "|`cumtime`|is the cumulative time spent in this and all subfunctions (from invocation till exit). This figure is accurate *even* for recursive functions|\n",
    "|`percall`|is the quotient of `cumtime` divided by primitive calls|\n",
    "|`filename:lineno(function)`|provides the respective data of each function|\n",
    "\n",
    "When there are two numbers in the first column (for example 3/1), it means that the function recursed. The second value is the number of primitive calls and the former is the total number of calls. Note that when the function does not recurse, these two values are the same, and only the single figure is printed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From IPython, the same result can be achieved by using the `%prun` magic command or `%%prun` cell magic command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "74f80c88e3b2e28583467dd95943bce5",
     "grade": false,
     "grade_id": "cprofile_2",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "%prun re.compile(\"foo|bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also possible to run a program under the profiler using the `%run` magic command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`%run -p [prof_opts] filename.py [args to program]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the command line, the cProfile module can be used as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "`python -m cProfile [-o output_file] [-s sort_order] filename.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using cProfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a toy example, we would like to evaluate the summation of the reciprocals of squares up to a certain integer $n$ for evaluating $\\pi$. The relation we want to use has been proven by Euler in 1735 and is known as the Basel problem.\n",
    "\n",
    "$\\pi^2 = 6 \\sum_{k=1}^{\\infty} \\frac{1}{k^2} = 6 \\lim_{k \\to \\infty} \\big( \\frac{1}{1^2} + \\frac{1}{2^2} + \\dots + \\frac{1}{k^2} \\big) \\approx 6 \\big( \\frac{1}{1^2} + \\frac{1}{2^2} + \\dots + \\frac{1}{n^2} \\big)$\n",
    "\n",
    "A simple Python function for evaluating the truncated sum looks like this:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recip_square(i):\n",
    "    return 1./i**2\n",
    "\n",
    "def approx_pi(n=10000000):\n",
    "    val = 0.\n",
    "    for k in range(1,n+1):\n",
    "        val += recip_square(k)\n",
    "    return (6 * val)**.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "First, start by timing how long it takes to evaluate the function using the default value of n.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "f4206405c247ec412fdb655f99722d13",
     "grade": true,
     "grade_id": "cprofile_3",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, profile the code using the `%prun` magic command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "99a48037609721afb0faf842fbc325c8",
     "grade": false,
     "grade_id": "cprofile_4",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%prun approx_pi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line of the profile contains the number of CPU seconds it took to run the code. You should see that the code was slower than the first run. This was because it ran inside the cProfile module. \n",
    "\n",
    "Looking at the `tottime` column, we can see that approximately half the time is spent in `approx_pi` and the other half is spent in `recip_square`. Also, we can see that considerable time is spent in the `range` function.\n",
    "\n",
    "Using information from the Python Performance Tips module, we know that there is considerable overhead in a function call, so let's try the same code without the extra function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "87790b9e34eac0a4f4d5e90245243b1e",
     "grade": false,
     "grade_id": "cprofile_5",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def approx_pi2(n=10000000):\n",
    "    val = 0.\n",
    "    for k in range(1,n+1):\n",
    "        val += 1./k**2\n",
    "    return (6 * val)**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "5bb5e845e1015656e23e580fbf3fefd0",
     "grade": false,
     "grade_id": "cprofile_6",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%prun approx_pi2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Examining the output from this command, you should see that a significant portion of time is still being spent in one function. Using your knowledge from the Python Performance Tips module, modify the code to reduce or eliminate this overhead. Enter the new code in the cell below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "e53c232af9b77469dd13345049c4b440",
     "grade": true,
     "grade_id": "cprofile_7",
     "locked": false,
     "points": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Now time how long it takes to run your version of the function.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "dee582e24a26fce505b1bebcc0734ec0",
     "grade": true,
     "grade_id": "cprofile_8",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Enter the speedup you achieved in the cell below using the equation $speedup = old time / new time$. E.g. if the old time was 2.21s and the new time was 340ms, then the speedup would be $2210 / 340$ or 6.5 times.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "c10ae9e565b52e0ccc2e697a782d18ad",
     "grade": true,
     "grade_id": "cprofile_9",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `line_profiler`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cProfile module shows how much time is being spent in each function. This is a good first step for locating hotspots in a program, and is frequently all that is needed to optimize the code. However, sometimes the cause of the hotspot is actually a single line in the function, and that line may not be obvious from just reading the source code. These cases are particularly frequent in scientific computing. Functions tend to be larger (sometimes because of legitimate algorithmic complexity, sometimes because the programmer is still trying to write FORTRAN code), and a single statement without function calls can trigger lots of computation when using libraries like NumPy. cProfile only times explicit function calls, not special methods called because of syntax. Consequently, a relatively slow NumPy operation on large arrays like this,\n",
    "\n",
    "```\n",
    "a[large_index_array] = some_other_large_array\n",
    "```\n",
    "\n",
    "is a hotspot that never gets explicitly shown by cProfile because there is no function call in that statement.\n",
    "\n",
    "The `line_profiler` can be given functions to profile, and it will time the execution of each individual line inside those functions. In a typical workflow, it is only useful to examine the line timings of a few functions because wading through the results of timing every single line of code would be overwhelming. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line profiler can be used from IPython by loading the `line_profiler` extension. Run the following command to load the extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "5254837edcba3cc6475f3d4f3073ba2c",
     "grade": false,
     "grade_id": "cprofile_10",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "The following code computes the list of prime numbers up to and including $n$ using the Sieve of Eratosthenes, which can be expressed in pseudocode as follows:\n",
    "\n",
    "**Input**: an integer $n > 1$\n",
    " \n",
    "Let $A$ be an array of Boolean values, indexed by integers $2$ to $n$,\n",
    "initially all set to **true**.\n",
    "\n",
    "```\n",
    "for i = 2, 3, 4, ..., not exceeding sqrt(n):\n",
    " if A[i] is true:\n",
    "  for j = i**2, i**2+i, i**2+2i, i**2+3i, ..., not exceeding n:\n",
    "    A[j] := false\n",
    "```\n",
    "\n",
    "**Output**: all $i$ such that $A[i]$ is **true**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "1f5ac472cce272c159138288b5b95314",
     "grade": false,
     "grade_id": "cprofile_11",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def primes(n=1000): \n",
    "    if n == 2:\n",
    "        return [2]\n",
    "    elif n < 2:\n",
    "        return []\n",
    "    s = range(3, n + 1, 2)\n",
    "    mroot = n ** 0.5\n",
    "    half = (n + 1) / 2 - 1\n",
    "    i = 0\n",
    "    m = 3\n",
    "    while m <= mroot:\n",
    "        if s[i]:\n",
    "            j = (m * m - 3)/2\n",
    "            s[j] = 0\n",
    "            while j < half:\n",
    "                s[j] = 0\n",
    "                j += m\n",
    "        i = i + 1\n",
    "        m = 2 * i + 3\n",
    "    return [2] + [x for x in s if x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have loaded this function, you can profile it with the line profiler using the following command. The \"`-f`\" option tells `%lprun` which function to profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "d844c1378193ae558fe4f345d5d8cfe6",
     "grade": false,
     "grade_id": "cprofile_12",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%lprun -f primes primes(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line profiler will display some information about the execution, including the line \"Timer unit:\" which gives the conversion factor to seconds for time information. It then shows a table with the following column headings (from left to right):\n",
    "\n",
    "|Heading|Description|\n",
    "|:---------|:----------|\n",
    "|`Line #`|The line number in the code|\n",
    "|`Hits`|The number of times that line was executed|\n",
    "|`Time`|The total amount of time spent executing the line in the timer's units|\n",
    "|`Per Hit`|The average amount of time spent executing the line once in the timer's unit|\n",
    "|`% Time`|The percentage of time spent on that line relative to the total amount of recorded time spent in the function|\n",
    "|`Line Contents`|The actual source code of the line|\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output, you can see that most of the time was spent at lines 15-17 and line 20. If we are to improve the performance of this function, then we should focus on these lines.\n",
    "\n",
    "As we have seen previously, one way of improving performance is to use builtin functions rather than Python code. Another way is to use a fast library such as NumPy to replace Python code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Using one or more of these techniques, write a new function called `faster_primes` that achieves better performance the the original function. Add your code to the cell below, and use the test cell to check the results.\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "29e34a9a0c52d77387044d587b3526fc",
     "grade": false,
     "grade_id": "cprofile_13",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def faster_primes(n=1000):\n",
    "    \"\"\"Fast implementation of the Sieve of Eratosthenes to compute prime numbers. Returns\n",
    "    a list of the first primes that are not greater than n.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following tests to ensure that your code is correct and results in a performance improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "78eaeb2ea962942fe649eb51424eb7cd",
     "grade": true,
     "grade_id": "cprofile_14",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/greg/anaconda/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 970, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/greg/anaconda/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 233, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/greg/anaconda/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 267, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/greg/anaconda/lib/python2.7/inspect.py\", line 1049, in getinnerframes\n",
      "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n",
      "  File \"/Users/greg/anaconda/lib/python2.7/inspect.py\", line 1009, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/greg/anaconda/lib/python2.7/inspect.py\", line 454, in getsourcefile\n",
      "    if hasattr(getmodule(object, filename), '__loader__'):\n",
      "  File \"/Users/greg/anaconda/lib/python2.7/inspect.py\", line 483, in getmodule\n",
      "    file = getabsfile(object, _filename)\n",
      "  File \"/Users/greg/anaconda/lib/python2.7/inspect.py\", line 467, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/Users/greg/anaconda/lib/python2.7/posixpath.py\", line 364, in abspath\n",
      "    cwd = os.getcwd()\n",
      "OSError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/Users/greg/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3083\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3084\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3085\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/greg/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 1880\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   1881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/greg/anaconda/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1240\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1242\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/greg/anaconda/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1148\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1150\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m             )\n\u001b[1;32m   1152\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/greg/anaconda/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1002\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/greg/anaconda/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0mrecords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecords\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/greg/anaconda/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mformat_records\u001b[0;34m(self, records)\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0mabspath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;31m#print '*** record:',file,lnum,func,lines,index  # dbg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "from nose.tools import assert_equal, assert_less\n",
    "import timeit\n",
    "assert_equal(primes(1000), faster_primes(1000))\n",
    "assert_less(timeit.timeit(faster_primes), timeit.timeit(primes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
